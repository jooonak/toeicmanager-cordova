"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments)).next());
    });
};
const util = require("util");
class MultipartUploadService {
    constructor($fs, $server, $serviceProxy, $hashService, $logger) {
        this.$fs = $fs;
        this.$server = $server;
        this.$serviceProxy = $serviceProxy;
        this.$hashService = $hashService;
        this.$logger = $logger;
    }
    uploadFileByChunks(filePath, bucketKey) {
        return __awaiter(this, void 0, void 0, function* () {
            let fileSize = this.$fs.getFileSize(filePath);
            let chunkStartByte = 0, endByte;
            yield this.$server.upload.initUpload(bucketKey);
            let chunks = [];
            while (chunkStartByte < fileSize) {
                endByte = chunkStartByte + MultipartUploadService.CHUNK_SIZE;
                if (endByte > fileSize) {
                    endByte = fileSize;
                }
                let chunkStream = this.$fs.createReadStream(filePath, { start: chunkStartByte, end: endByte });
                let promise = this.uploadChunk(bucketKey, chunkStartByte, endByte, chunkStream, fileSize);
                chunks.push(promise);
                chunkStartByte = endByte;
                if (chunks.length === MultipartUploadService.MAX_CONCURRENT_UPLOADS) {
                    yield Promise.all(chunks);
                    chunks = [];
                }
            }
            if (chunks.length > 0) {
                yield Promise.all(chunks);
            }
            let fileHash = yield this.$hashService.getFileHash(filePath, MultipartUploadService.INPUT_FILE_ENCODING, MultipartUploadService.HASH_ALGORITHM, MultipartUploadService.HASH_ENCODING);
            yield this.$server.upload.completeUpload(bucketKey, fileHash);
        });
    }
    uploadChunk(path, startingIndex, endIndex, content, fileSize) {
        return __awaiter(this, void 0, void 0, function* () {
            let headers = {
                "Content-Range": util.format("bytes %d-%d/%s", startingIndex, endIndex - 1, fileSize),
                "Content-Length": endIndex - startingIndex
            };
            this.$logger.trace("Uploading chunk with Content-Range: %s", headers["Content-Range"]);
            return this.$serviceProxy.call('UploadChunk', 'PUT', ['api', 'upload', encodeURI(path.replace(/\\/g, '/'))].join('/'), null, [{ name: 'content', value: content, contentType: 'application/octet-stream' }], null, headers);
        });
    }
}
MultipartUploadService.CHUNK_SIZE = 1024 * 1024 * 20;
MultipartUploadService.INPUT_FILE_ENCODING = "binary";
MultipartUploadService.HASH_ALGORITHM = "sha512";
MultipartUploadService.HASH_ENCODING = "base64";
MultipartUploadService.MAX_CONCURRENT_UPLOADS = 3;
exports.MultipartUploadService = MultipartUploadService;
$injector.register("multipartUploadService", MultipartUploadService);
